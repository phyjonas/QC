{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cirq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will discuss the ideas behind the Variational-Quantum-Eigensolver. This algorithm relies on the variational principle and is used to find the ground state of a quantum system (and therefore, more generally speaking extracts the lowest eigenvalue of a hermitian matrix). However, contrary to the standard setting of computational physics, the wavefunction here is not parameterised on a classical computer but by a quantum circuit. We also note that many classical optimisation problems can be mapped onto quantum Hamiltonians, and then finding the ground state becomes equivalent to minimising the cost function.\n",
    "\n",
    "The quantum circuit is then used to estimate the expectation value of the energy, while the parameter optimisation is done classically. The main hope here is that, especially for many-body systems/ exponentially large matrices, the estimation of the energy can be done much more efficiently on a quantum computer than on a classical computer (wherein the setting of many-body physics one usually relies on Monte Carlo type estimations).\n",
    "We note that, in general, the problem is in QMA and, therefore, still hard for a quantum computer. Nevertheless, it is a promising idea that can also be combined with domain knowledge to chose a suitable trial wavefunction.\n",
    "We also note that this is an active research topic, and there are many details, which we will not cover to make this algorithm efficient. \n",
    "\n",
    "The intent of this notebook is instead to outline the idea behind the algorithm and show a simple working example.\n",
    "\n",
    "Reading: Quantum Sci. Technol. 3 030503, ncomms5213, arXiv:1407.7863"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before describing the VQE let's very briefly review the variational principle in quantum mechanics. \n",
    "\n",
    "First, let $\\mathcal{H}$ be a Hilbertspace (on a qubit system this will always be finite dimensional but in principle it doesn't have to be),  $|\\psi\\rangle$ a normalised state $\\in \\mathcal{H}$ and $H$ a hermitian operator (in our case it's simply a hermitian matrix) over $\\mathcal{H}$. We note that using the spectral theorem we can write $H = \\sum_i E_i | i\\rangle \\langle i|$ (where we ordered the $E_i$ in ascending order) \n",
    "It is then easy to see that\n",
    "\\begin{equation}\n",
    "\\langle\\psi| H |\\psi \\rangle = \\sum_i E_i |\\langle i|\\psi \\rangle|^2 \\geq \\sum_i E_0 |\\langle i|\\psi \\rangle|^2 = E_0.\n",
    "\\end{equation}\n",
    "This simply means that any expectation value of $H$ is an upper bound of the groundstate energy. The idea of the variational ansatz is now simple. One parameterises the wave-function by a set of paramters $\\theta$ and minimises the resulting expecation value $\\langle\\psi(\\theta)| H |\\psi(\\theta) \\rangle$. Depending on the how well the wavefunction is chosen the result will be close to the true groundstate of the system. In fact for a finite dimensional Hilbertspace we could in theory span the whole Hilbertspace with a finite number of $\\theta$ and then find the true groundstate, in practice this is of course untracable for larger systems. \n",
    "At this stage we can already see that domain knowledge can be a great benefit when chosing the trial wavefunction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{theorem}\n",
    "The VQE algorithm works as follows\n",
    "\n",
    "1. Prepare $|\\psi(\\theta)\\rangle$ (or more generally $\\rho(\\theta)$)\n",
    "2. Meassure $\\langle H\\rangle(\\theta) = E(\\theta)$.\n",
    "3. Use a classical optimisation scheme to update $\\theta$\n",
    "4. Iterate 1-3 until desired convergence is achieved \n",
    "\\end{theorem}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly see that this type of algorithm is extremly general and there are many possible ways to realise such a scheme. One does not even have to use a gate-based quantum computer for this. \n",
    "\n",
    "In the following we will go through a simple example to demonstrate how a simplified implementation could look like. This implementation is far from optimal but serves as a concrete example to illustrate the concept. We also note that the exact details of an efficient implementation of such an algorithm is an active research field and will depend on the hardware at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before finally turning to the example we want to quickly note, that the tensor product of Pauli operators spans the space of Hermitian matricies and it is therfore in principle enough to restric ourselves to Hamiltonians made up of tensor products of Pauli operators. In quantum chemistry for example this mapping can be made explicit by a Jordan-Wigner (or  Bravyiâˆ’Kitaev) transformation.\n",
    "\n",
    "Let's consider the two qubit Hamiltonian\n",
    "\\begin{equation}\n",
    "H = X_1 + 0.1Z_1 - Z_2 + 0.5 X_1Z_2 + 0.3Z_1Y_2\n",
    "\\end{equation}\n",
    "Before we get into the details on how to perform 2. \n",
    "Let's think about a suitable variational Ansatz. \n",
    "Here we already see two competing principles. \n",
    "\n",
    "On the one hand we want our Ansatz to be simple (meaning as few parameters as possible and keeping the circuit depth as shallow as possible, while also respecting the current hardware limitations) and on the other hand we want it to ideally span the Hilbert space or at least the relevant part of the Hilbert space. Again the optimal trade-off can vary from problem to problem and it is a priori far from trivial to chose a good variational Ansatz.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{remark}\n",
    "For the example at hand it we recall that state of a two-level system can be discribed as by two real numbers (since only the relative phase has a physical meaning and the state is normalised), one such choice (and perhaps the most common one) is the position on the Bloch sphere, which is given by $\\phi, \\theta$. \n",
    "In order to make use of the existing gates another approach is taken. We recall that any unitary transformation of a qubit state can be thought of as a rotation on the Bloch ssphere and we therefore have to consider only $SU(2)$. This can of course be generalised to $n$ qubits, where we would now have to consider $SU(2^n)$, to parametrise any unitary transformation on the Bloch sphere, realising that $\\mathrm{dim}[SU(2^n)] =4^n-1$ we conclude that we need at least $4^n-1$ parameters, if we only have access to rotational and $CNOT$ gates. We also recall that using the Euler represntation of $SU(2)$ any element $U\\in SU(2)$  can be written as $U= R_z(\\phi)R_y(\\theta)R_z(\\psi)$.\n",
    "\\end{remark}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now parametrise some circuits. In order to gain some more insight we will implement two-qubit circuits with increasing complexity, and one universal circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement universal SU(2) gate\n",
    "def U_single_qubit(q,phi,theta,psi):\n",
    "    yield cirq.rz(phi)(q)\n",
    "    yield cirq.ry(theta)(q)\n",
    "    yield cirq.rz(psi)(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the KAK decomposition of $SU(4)$ we can implement a universal $SU(4)$ unitary operator and using it as our variational Ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def universal_va(q1,q2,parameters):\n",
    "    yield U_single_qubit(q1,*parameters[0])\n",
    "    yield U_single_qubit(q2,*parameters[1])\n",
    "    yield cirq.CNOT(q1,q2)\n",
    "    yield U_single_qubit(q1,*parameters[2])\n",
    "    yield U_single_qubit(q2,*parameters[3])\n",
    "    yield cirq.CNOT(q2,q1)\n",
    "    yield U_single_qubit(q1,*parameters[4])\n",
    "    yield cirq.CNOT(q1,q2)\n",
    "    yield U_single_qubit(q1,*parameters[5])\n",
    "    yield U_single_qubit(q2,*parameters[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has circuit has 21 free parameters let's also initialise a simpler circuit, that can not span the whole space (feel free to implement your own ciruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_uni_va(q1,q2,parameters):\n",
    "    yield U_single_qubit(q1,*parameters[0])\n",
    "    yield U_single_qubit(q2,*parameters[1])\n",
    "    yield cirq.CNOT(q1,q2)\n",
    "    yield U_single_qubit(q1,*parameters[2])\n",
    "    yield U_single_qubit(q2,*parameters[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get to step 2. Here we have to meassure the Hamoltonian again this step can be done in many different way and the most efficient way of doing so can depend on the underlying structure of the problem.\n",
    "\n",
    "When considering a general Hamlitonian one can now devise two different straightforward strategies\n",
    "\\begin{enumerate}\n",
    "\\item Measure the state in the computational basis calculate $E(\\theta)$, repeat until the result is coverged\n",
    "\\item Perform direct Pauli measurments using the quantum circuit, calculate $E(\\theta)$ from those individual measurments\n",
    "\\end{enumerate}\n",
    "The first option is cloesly related to standard Monte Carlo methods, the only difference here is that the cirucit naturally implements the improtance sampling according to the wave-function. Here at each step the whole Energy is estimated. A major drawback of this approach is, that to achieve convergence we might have so sample many times and in principle we still have to perform large matrix multiplications on a classical computer\n",
    "\n",
    "The second option has the major advantage, is that we measure the expectation values in a suitable basis and therefore the outcome of ony term is just the coefficient multiplied by $\\pm 1$, to caculate the expectation value we now have to nothing but averaging over many measurments without having to perfrom any matrix multiplications. Here in each run a single expectation value is measured for each term in the Hamiltonian (using clever grouping it is possible to measure more than one term).\n",
    "\n",
    "Usually the second method is to be preferred since it does not involve large matricies (which is usually one of the bottlenecks on a classical computer).\n",
    "In order to measure the values of a pauli-matrix in a suitable basis we now define the functions, which meassure in the X, Y basis. The Z-basis is the computational one.\n",
    "\n",
    "In order to meassure with respect to the X (Y) basis we just need to find the operator that transforms from the eigenbasis to the computational basis. For X this is simply the Hadamard gate and for Y it is $S^\\dagger H$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_measurment(q):\n",
    "    yield cirq.H(q)\n",
    "    \n",
    "def y_measurment(q):\n",
    "    Sdagger = (cirq.Z**(-0.5))\n",
    "    yield Sdagger(q)\n",
    "    yield cirq.H(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many measurments we have to make to get one estimate for the energy.\n",
    "We see that we can rewrite \n",
    "\\begin{equation}\n",
    "H = X_1 + 0.1Z_1 - Z_2 + 0.5 X_1Z_2 + 0.3Z_1Y_2 = [X_1(1+0.5Z_2) -Z_2]+Z_1(0.1+0.3Y_2) = H_1+H_2,\n",
    "\\end{equation}\n",
    "which shows us that in fact two measurments are enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this implementation is not really efficent and could be improved but it shows the individual steps nicely\n",
    "def H_1_measurment(q1,q2):\n",
    "    yield x_measurment(q1)\n",
    "    yield cirq.measure(q1,q2, key='H_1')\n",
    "\n",
    "def H_2_measurment(q1,q2):\n",
    "    yield y_measurment(q2)\n",
    "    yield cirq.measure(q1,q2, key='H_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E1_curcuit(va,parameters):\n",
    "    q1, q2 =cirq.LineQubit.range(2)\n",
    "    c = cirq.Circuit()\n",
    "    c.append(va(q1,q2,parameters))\n",
    "    c.append(H_1_measurment(q1,q2))\n",
    "    return c\n",
    "\n",
    "def E2_curcuit(va,parameters):\n",
    "    q1, q2 =cirq.LineQubit.range(2)\n",
    "    c = cirq.Circuit()\n",
    "    c.append(va(q1,q2,parameters))\n",
    "    c.append(H_2_measurment(q1,q2))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = cirq.Simulator()\n",
    "def transform_to_eigenvalue(measurements):\n",
    "    return [[1 if i == 0 else -1 for i in j ] for j in measurements]\n",
    "\n",
    "def H_estimator(parameters,N,va):\n",
    "    parameters = [[parameters[i+j] for j in range(3)] for i in range(7)]\n",
    "    c1 = E1_curcuit(va,parameters)\n",
    "    c2 = E2_curcuit(va,parameters)\n",
    "    r1 = simulator.run(c1,  repetitions=N)\n",
    "    r2 = simulator.run(c2,  repetitions=N)\n",
    "    m1 =transform_to_eigenvalue(r1.measurements['H_1'])\n",
    "    m2 =transform_to_eigenvalue(r2.measurements['H_2'])\n",
    "    mean = 0 \n",
    "    for i in zip(m1,m2):\n",
    "        mean += i[0][0]*(1+1/2*i[0][1])-i[0][1]+i[1][0]*(0.1+0.3*i[1][1])\n",
    "    return mean/N\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now implemented step 2. Lastly it we want to perform step 3. and then we can compare our results to those obtained by exact diagonalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 3. relies on a classical optimisation algorithm there are many algorithms to chose from. Maybe a very naive guess would be gradient decent. In pratice (for reasons not that we will not discuss here see arXiv:1509.04279) this peforms relatively poorly in practice.  \n",
    "\n",
    "Here we will use the Nelder-Mead simplex method as it is a derivative free optimisation method again see for arXiv:1509.04279 a discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_va_opt = scipy.optimize.minimize(H_estimator \n",
    "                                     , x0=2*np.pi*np.random.rand(21), args=(5000, universal_va) \n",
    "                                     ,method='Nelder-Mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.4318799999999947"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_va_opt.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_uni_va_opt= scipy.optimize.minimize(H_estimator \n",
    "                                     , x0=2*np.pi*np.random.rand(12), args=(5000, non_uni_va) \n",
    "                                     ,method='Nelder-Mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.2976799999999775"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_uni_va_opt.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly let's check our result against the result obtained using exact diagonalisation.\n",
    "As a reminder we want to diagonalise the Hamiltonian follwoing\n",
    "\\begin{equation}\n",
    "H = X_1 + 0.1Z_1 - Z_2 + 0.5 X_1Z_2 + 0.3Z_1Y_2 \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Exact diagonalisation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,1],[1,0]])\n",
    "Z = np.array([[1,0],[0,-1]])\n",
    "Y = np.array([[0,-1j],[1j,0]])\n",
    "I = np.array([[1,0],[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = np.kron(X,I)+0.1*np.kron(Z,I)-np.kron(I,Z)+0.5*np.kron(X,Z)+0.3*np.kron(Z,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9+0.j ,  0. -0.3j,  1.5+0.j ,  0. +0.j ],\n",
       "       [ 0. +0.3j,  1.1+0.j ,  0. +0.j ,  0.5+0.j ],\n",
       "       [ 1.5+0.j ,  0. +0.j , -1.1+0.j ,  0. +0.3j],\n",
       "       [ 0. +0.j ,  0.5+0.j ,  0. -0.3j,  0.9+0.j ]])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.525761723698866"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##exact result\n",
    "np.min(np.linalg.eigh(H)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both of our variational wavefunctions performed fairly well. Some of the error is also attributed to the noise of evaluating the expectation value. It also shows us that in most cases it is not neccessary to chose a universal approximator of the wavefunction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
